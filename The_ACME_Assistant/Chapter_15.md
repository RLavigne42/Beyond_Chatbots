## Part IV: Applications & Horizons (The Trusted Team Member)

**Prologue to Part IV:** We have reached the final stage of our journey. The "Prodigy" is no longer a newcomer. They have been through the Onboarding Framework (Foundations), completed their Specialized Training (Enrichment), and are now operating within a high-security stadium (Systems in the Wild).

In this final section, we move from the **How** to the **So What**. We will implement three distinct, high-impact "Jobs" that represent the most common and valuable patterns for AI in the enterprise.

---

## Chapter 15: Case Study ‚Äî The Enterprise Knowledge Assistant

The Manager‚Äôs first major project for the Assistant was the **Librarian**. ACME had thousands of pages of scattered documentation‚ÄîWikis, PDFs, Slack threads, and Google Docs. Employees were losing hours every week just looking for answers, often finding outdated versions of policies. The goal was simple: one chat box that knows everything the company knows, in real-time.

In this chapter, we apply our **RAG** and **Hybrid Search** skills to build a production-grade information retrieval system that users can actually trust.

---

### 15.1 The Challenge: Multi-Source Fragmentation

The data wasn't just in one neat folder. It was living in different worlds, each with its own language:

* **The Wiki (Confluence):** Structured, but often long-winded.
* **The Messy Drive (Google Drive):** Full of drafts, images, and legacy spreadsheets.
* **The Stream (Slack):** Where "tribal knowledge" lives in short, unformatted bursts.

**What & Why: The Unified Connector**

* **What it is:** A layer that pulls from all these sources and standardizes them into the **Markdown Index Cards** we built in Chapter 5.
* **Why we need it:** If the Assistant only knows the Wiki, it misses the context of the conversations happening in Slack.

---

### 15.2 The Implementation: Scoped Retrieval

The Manager knew that a "one-size-fits-all" search was dangerous. If an entry-level intern asks about salaries, the Assistant shouldn't go digging in the HR Restricted folder.

**The Logic: Metadata Scoping**
We use the **Metadata** from Chapter 5 to create "Virtual Walls."

1. **Identity Check:** The system identifies the user's role (e.g., `Engineering`).
2. **Filter:** The RAG search is restricted to chunks where `access_level` matches `Engineering` or `Public`.
3. **Retrieve:** The Prodigy only sees the facts they are authorized to know.

---

### 15.3 Provenance: The "Show Your Work" UI

In an Enterprise setting, a "good answer" isn't enough. People need to see the **Proof**.

**The Intuitive Analogy: The Footnotes**
Imagine the Prodigy gives a great answer about the 401k match. The Manager asks, "Where did you get that?" The Assistant points to the exact paragraph in the `2026_Benefits_Summary.pdf`. This builds trust and allows the human to verify the AI's "homework."

**The What & Why: Citation Highlighting**

* **What it is:** Mapping the specific "Chunk ID" back to the exact page and line number in the source document.
* **Why we need it:** It transforms the Assistant from a "black box" into a transparent research tool.

---

### üõ†Ô∏è Hands-On Lab: "Building the Knowledge Librarian"

**Goal:** Build a multi-source RAG system that respects user roles and provides clickable citations.

**Step 1: The Multi-Source Ingestor**
Create a script that pulls one page from a Wiki (Mock HTML) and one message from a chat (Mock JSON). Use your Chapter 5 logic to turn both into standard chunks.

**Step 2: Scoped Search**
Update your Chapter 6 `retrieve()` function to accept a `user_role` parameter. Ensure the vector search only returns chunks the user is allowed to see.

**Step 3: The Citation Wrapper**
Update the Orchestrator so the final answer includes a `sources` array:

```json
{
  "answer": "The holiday policy allows 20 days...",
  "sources": [{"title": "Employee Handbook", "url": "https://acme.com/docs/123", "page": 4}]
}

```

**Acceptance Criteria:**

* The Assistant refuses to answer questions based on "HR-only" documents when the user is "General."
* Every answer includes at least one verifiable source link.
* The "Judge" (from Ch 12) confirms that the answer is 100% grounded in the provided sources.

---

### üö© Anti-Patterns: Manager's Warnings

* **"The Data Swamp":** Don't ingest every version of a document. If you have "Policy_Final_v1" and "Policy_Final_v2," the Assistant will get confused. You must implement a "Master Record" policy.
* **"Blind Citations":** Don't let the model make up links. Ensure your code injects the *real* URLs from the metadata, not the ones the model "thinks" look right.

---

### Checklists: Knowledge Assistant Readiness

* [ ] Role-Based Access Control (RBAC) integrated into the vector search.
* [ ] Source connectors (Confluence/Slack/Drive) are authenticated.
* [ ] UI supports displaying citations and source links.

**What's Next:**
The Librarian is a huge win for productivity. But the Sages want more‚Äîthey want to talk to the company's *numbers*. In **Chapter 16: Case Study ‚Äî The Analytics Copilot**, we teach our Assistant how to turn plain English into complex database queries.
